{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "import openai\n",
    "from langchain_groq import ChatGroq\n",
    "#GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"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\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model = \"llama-3.1-70b-versatile\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20448\\572361986.py:5: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import initialize_agent\n",
    "tool=load_tools([\"wikipedia\"],llm=llm)\n",
    "agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-built Tools LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
      "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "class calc(BaseTool):\n",
    "    \n",
    "    name : str= \"Circumference calculator\"\n",
    "    description : str = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n",
    "\n",
    "    def _run(self, radius):\n",
    "        return float(radius)*2.0*3.14\n",
    "\n",
    "    def _arun(self, radius: int):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ನಾನು ಪ್ರೋಗ್ರಾಮಿಂಗ್ ಅನ್ನು ಪ್ರೀತಿಸುತ್ತೇನೆ.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 53, 'total_tokens': 127, 'completion_time': 0.269090909, 'prompt_time': 0.008840651, 'queue_time': 0.24513799899999997, 'total_time': 0.27793156}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_76dc6cf67d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f05fb13c-2a78-4288-a474-83c88dc4de36-0', usage_metadata={'input_tokens': 53, 'output_tokens': 74, 'total_tokens': 127})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    model = \"llama-3.1-70b-versatile\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2   \n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the usersentence to Kannada.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "WOLFRAM_ALPHA_URL = 'http://api.wolframalpha.com/v2/query'\n",
    "\n",
    "client = openai.OpenAI()\n",
    "math = client.chat.completions.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are an expert mathematician who can perform complex math operations with reasoning and proofs.'},\n",
    "        {'role': 'user', 'content': 'Please answer the query.'}\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=2048,\n",
    "    top_p=0.7,\n",
    ")\n",
    "\n",
    "def query_wolfram_alpha(query):\n",
    "    \"\"\"\n",
    "    Sends a query to Wolfram Alpha API and returns the response.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'input': query,\n",
    "        'appid': os.environ.get('WRAM_API_KEY'),\n",
    "        'format': 'plaintext'\n",
    "    }\n",
    "    response = requests.get(WOLFRAM_ALPHA_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return \"Error querying Wolfram Alpha.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def preprocess_query(text):\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        model_name='gpt-4o-mini',\n",
    "        encoding_name='text-embedding-3-small',\n",
    "        )\n",
    "\n",
    "    split_text = splitter.split_text(text)\n",
    "    split_text\n",
    "\n",
    "    return model.invoke(f'convert {split_text} into wolfram alpha efficient form')\n",
    "\n",
    "def preprocess_result(text):\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        model_name='gpt-4o-mini',\n",
    "        encoding_name='text-embedding-3-small',\n",
    "        )\n",
    "\n",
    "    split_text = splitter.split_text(text)\n",
    "    split_text\n",
    "\n",
    "    return model.invoke(f'convert {split_text} into a easily understandable form')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(input_variables=[\"input\", \"tools\", \"agent_scratchpad\", \"tool_names\"], template=template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tool(BaseTool):\n",
    "    \n",
    "    name: str = \"wolfram_llama_tool\"\n",
    "    description: str = \"A tool that integrates Wolfram Alpha and LLaMA model for computational queries.\"\n",
    "\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        \"\"\"\n",
    "        Internal run method (used for async execution in LangChain).\n",
    "        \"\"\"\n",
    "        return self.invoke(query)\n",
    "\n",
    "\n",
    "    def invoke(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Custom invoke method for the WolframLlamaTool.\n",
    "        \"\"\"\n",
    "        # Process query with LLaMA (optional, can be used for preprocessing)\n",
    "        #processed_query = preprocess_query(query)\n",
    "        \n",
    "        # Send the processed query to Wolfram Alpha\n",
    "        wolfram_response = query_wolfram_alpha(query)\n",
    "        \n",
    "        # Optionally, process the Wolfram response with LLaMA\n",
    "        #final_response = preprocess_result(wolfram_response)\n",
    "        \n",
    "        return wolfram_response.format(template)\n",
    "    \n",
    "cust = tool()\n",
    "circ = calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=model,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "        verbose=True\n",
    "    ),\n",
    "    Tool(name=\"wolfram_llama_tool\",\n",
    "         func=cust._run,\n",
    "         description=\"A tool that integrates Wolfram Alpha and LLaMA model for computational and theoritical queries.\",\n",
    "         verbose=True\n",
    "    ),\n",
    "    Tool(name=\"Circumference Calculator\",\n",
    "         func=circ._run,\n",
    "         description=\"A tool that finds circumference of any circle of known radius\",\n",
    "         verbose=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate the circumference of a circle, we need to use the formula C = 2πr, where C is the circumference and r is the radius. Since we have the radius, we can directly use the Circumference Calculator tool.\n",
      "\n",
      "Action: Circumference Calculator\n",
      "Action Input: 3.14\u001b[0m\u001b[38;5;200m\u001b[1;3m19.7192\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: The circumference of the circle with radius r = 3.14 is 19.7192.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo integrate $e^{x^2}$ from 0 to infinity, we first need to determine if the function is integrable over this interval. The function $e^{x^2}$ is a Gaussian function, which is known to be integrable over the real line, but the integral does not have an elementary antiderivative. However, we can use the properties of Gaussian functions and special functions to evaluate this integral.\n",
      "\n",
      "Thought: Since this problem involves integration and special functions, we should use the wolfram_llama_tool to find the integral and the step-by-step process.\n",
      "\n",
      "Action: wolfram_llama_tool\n",
      "Action Input: integrate e^x^2 from 0 to infinity\u001b[0m\u001b[33;1m\u001b[1;3m<?xml version='1.0' encoding='UTF-8'?>\n",
      "<queryresult success='true'\n",
      "    error='false'\n",
      "    xml:space='preserve'\n",
      "    numpods='2'\n",
      "    datatypes=''\n",
      "    timedout=''\n",
      "    timedoutpods=''\n",
      "    timing='0.7000000000000001'\n",
      "    parsetiming='0.336'\n",
      "    parsetimedout='false'\n",
      "    recalculate=''\n",
      "    id='MSP7431dadce503bg8bd30000036h2c206f8a29f8a'\n",
      "    host='https://www6b3.wolframalpha.com'\n",
      "    server='19'\n",
      "    related='https://www6b3.wolframalpha.com/api/v1/relatedQueries.jsp?id=MSPa7441dadce503bg8bd30000018911ddaf80igf257179915770051379692'\n",
      "    version='2.6'\n",
      "    inputstring='integrate e^x^2 from 0 to infinity'>\n",
      " <pod title='Input'\n",
      "     scanner='Integral'\n",
      "     id='Input'\n",
      "     position='100'\n",
      "     error='false'\n",
      "     numsubpods='1'>\n",
      "  <subpod title=''>\n",
      "   <plaintext>integral_0^∞ e^(x^2) dx</plaintext>\n",
      "  </subpod>\n",
      "  <expressiontypes count='1'>\n",
      "   <expressiontype name='Default' />\n",
      "  </expressiontypes>\n",
      " </pod>\n",
      " <pod title='Result'\n",
      "     scanner='Integral'\n",
      "     id='DefiniteIntegral'\n",
      "     position='200'\n",
      "     error='false'\n",
      "     numsubpods='1'\n",
      "     primary='true'>\n",
      "  <subpod title=''>\n",
      "   <plaintext>(integral does not converge)</plaintext>\n",
      "  </subpod>\n",
      "  <expressiontypes count='1'>\n",
      "   <expressiontype name='Default' />\n",
      "  </expressiontypes>\n",
      " </pod>\n",
      "</queryresult>\u001b[0m\u001b[32;1m\u001b[1;3mThought: The wolfram_llama_tool output indicates that the integral of $e^{x^2}$ from 0 to infinity does not converge. This means that the function is not integrable over this interval.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: The integral of $e^{x^2}$ from 0 to infinity does not converge, meaning the function is not integrable over this interval.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Integrate e^x2 from 0 to infinity if the function is integrable and also show the step by step process',\n",
       " 'output': 'The integral of $e^{x^2}$ from 0 to infinity does not converge, meaning the function is not integrable over this interval.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_agent(model, tools, prompt=template)\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True,handle_parsing_errors=True)\n",
    "\n",
    "agent_executor.invoke({\n",
    "    \"input\": \"Calculate circumference of the circle with radius r = 3.14\"\n",
    "    })\n",
    "\n",
    "agent_executor.invoke({\n",
    "    \"input\": \"Integrate e^x2 from 0 to infinity if the function is integrable and also show the step by step process\"\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
